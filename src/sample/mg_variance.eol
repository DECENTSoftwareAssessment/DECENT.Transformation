import "../mg/mg_hunks.eol";
import "../../epsilon/libraries/decent/common.eol";

//changed lines
// Before After	After After
// 1  		1		1
// 2*  	*	2*	*	2*
// 3  		3		3
//    	+	4+	-
//    	+	5+	-
//    	+	6+	-
// 4  		7		4
// 5  		8		5
// 6*  	*	9*	*	6*
// 7  		10		7


// 1-  	-			1
// 2*  	*	1*	*	2*
// 3  		2		3
//    	+	3+	-
//    	+	4+	-
//    	+	5+	-
// 4  		6		4
// 5  		7		5
// 6*  	*	8*	*	6*
// 7  		9		7

// No. // Before              After        
// (1) // 1-         -        
// (2) // 2*         *        1*
// (3) // 3                   2
// (4) //            +        3+
// (5) //            +        4+
// (6) //            +        5+
// (7) // 4                   6
// (8) // 5                   7
// (9) // 6*         *        8*
// (10)// 7                   9
var points = new Set;

points.add(1);
points.add(3);
points.add(4);
points.add(5);
points.add(8);
//points.add(71);

//("Variance After = "+points.getMyVariance()).println();
//("Variance = "+points.getVariance()).println();
//("Variance = "+points.getNaiveVariance()).println();

var pointsBefore = new Set;

pointsBefore.add(1);
pointsBefore.add(2);
pointsBefore.add(6);

("Variance Before = "+pointsBefore.getMyVariance()).println();
("Variance After = "+points.getMyVariance()).println();

var pointsAA = new Set;

pointsAA.add(1);
pointsAA.add(2);
pointsAA.add(3);
pointsAA.add(4);
pointsAA.add(5);
pointsAA.add(6);
pointsAA.add(7);
pointsAA.add(8);
pointsAA.add(9);
pointsAA.add(10);

("Variance After After = "+pointsAA.getMyVariance()).println();


var pointsRelative = new Set;

pointsRelative.add(1);
pointsRelative.add(2);
pointsRelative.add(7);
pointsRelative.add(9);

("Variance Relative = "+pointsRelative.getMyVariance()).println();

var pointsAbsolute = new Set;

var offset = 100;

for (r in pointsRelative) {
	pointsAbsolute.add(r+offset);
}


("Variance Absolute = "+pointsAbsolute.getMyVariance()).println();



//processHunks();

//getTimeVariane();
//getSpatialIndex();


operation processHunks() {
    var files = MG!File.allInstances();

    for (f in files) {
        (f.file_name).println();
        for (a in f.actions) {
       		var hunks = f.hunks.select(h|h.revision = a.revision);
       		hunks.sortHunks();
       		hunks.normalizeHunks();
       		hunks.getSpatialIndex();
       }
    }
}

operation OrderedSet getSpatialIndex() {
	var difference = 0;
	//this may need to be revised, new lines need to be put in full context
	//on the other hand the difference may need to be reviewed as well ignoring the context
	//review and validate
	var linesPre = new OrderedSet;
	var linesPost = new OrderedSet;
	var linesMerged = new OrderedSet;
	var difference = 0;
	for (h in self) {
		var o = h.old_start_line+":"+h.old_end_line+
			"->"+h.new_start_line+":"+h.new_end_line;
		("  Base:       "+o).println;
		
		//split, potentially remove normalized
		var on = h.~old_start_line_normalized+":"+h.~old_end_line_normalized+
			"->"+h.~new_start_line_normalized+":"+h.~new_end_line_normalized;
		("  Normalized: "+on).println;

	    //handle context of +/- 1 line 
		var i = -1;
		var j = 0;
		if (h.old_start_line <> 0) {
		    j = 1;
		}
		while (h.~old_start_line_normalized+i <= h.~old_end_line_normalized+j) {
			linesPre.add(h.~old_start_line_normalized+i);
			if (h.~difference < 0) {
			   linesMerged.add(h.~old_start_line_normalized+i);
			}
			("  Pre: "+(h.~old_start_line_normalized+i)).println;
			i = i+1;
		}
		i = -1;
		j = 0;
        if (h.new_start_line <> 0) {
            j = 1;
        }
		while (h.~new_start_line_normalized+i <= h.~new_end_line_normalized+j) {
			linesPost.add(h.~new_start_line_normalized+i);
	        linesMerged.add(h.~new_start_line_normalized+i);
			i = i+1;
		}
	}
	var h = self.first;
	//TODO: add separate values for normalized and contextualized calculations
    ("      "+h.file.file_name +" in "+h.revision.commit_id+" Lines Before "+linesPre).println();
	("      "+h.file.file_name +" in "+h.revision.commit_id+" Lines After  "+linesPost).println();
    ("      "+h.file.file_name +" in "+h.revision.commit_id+" Lines Merged "+linesMerged).println();
	
	("      "+h.file.file_name +" in "+h.revision.commit_id+" Old Spatial Index "+linesPre.getMyVariance()).println();
	("      "+h.file.file_name +" in "+h.revision.commit_id+" New Spatial Index "+linesPost.getMyVariance()).println();
	("      "+h.file.file_name +" in "+h.revision.commit_id+" Merged Spatial Index "+linesMerged.getMyVariance()).println();
		
}

operation getTimeVariane() {
	var revisions = MG!Revision.allInstances();
	var relativeTime = new Set;
	var absoluteTime = new Set;
	
	var last = null;
	var first = null;
	for (r in revisions) {
		var distanceToLast = 0;
		var distanceToFirst = 0;
		if (last.isDefined()) {
			distanceToLast = r.commit_date.getTime - last.commit_date.getTime;
		} else {
			first = r;
		}
		distanceToFirst = r.commit_date.getTime - first.commit_date.getTime;
		("Revision "+r.commit_id+", Date "+r.commit_date.getTime + ", Distance to last "+ distanceToLast + ", Distance to first "+distanceToFirst).println();
		relativeTime.add(distanceToLast);
		absoluteTime.add(distanceToFirst);
		last = r;
	}
	
	("Absolute Time Variance = "+absoluteTime.getMyVariance() +
	" ("+
	(absoluteTime.getMyVariance()/(3600*1000*24))
	+" days)").println();
	("Relative Time Variance = "+relativeTime.getMyVariance() + 
	" ("+
	(absoluteTime.getMyVariance()/(3600*1000*24))
	+" days)").println();
}


operation Set getMyVariance() : Real {
    var n = 0.asReal();
    var sum = 0.asReal();
    for (x in self){
        n = n + 1;
        sum = sum + x;
    }
    
    var sum2 = 0.asReal();
    
    for (x in self){
		sum2 = sum2 + (x - sum/n)*(x - sum/n);	
	}
	var variance = sum2/(n-1).asReal();
	return variance;
}

operation Set getNaiveVariance() : Real {
    var n = 0.asReal();
    var sum = 0.asReal();
    var sum_sqr = 0.asReal();
    for (x in self){
        n = n + 1;
        sum = sum + x;
        sum_sqr = sum_sqr + x*x;
    }
 
    var variance = (sum_sqr - (sum*sum)/n)/(n - 1);
    return variance;
}

